{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "991b4f39-1425-439e-acfe-43946404c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use file Weekly_Quizzes1_3_copy.docx%20(1).pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e5e32a4-615e-4bbc-af78-54cf5e662ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure 1: Food Type Prediction\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"./q1and2.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "print(\"Figure 1: Food Type Prediction\")\n",
    "Image(url= \"./q1and2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff75f2f1-5180-4f04-8eaa-f5da5f68d6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Food Name  Sugar content  Crunchiness  Food Type  Distance\n",
      "15    Tomato              6            4    Unknown  0.000000\n",
      "0     Orange              7            3      Fruit  1.414214\n",
      "1      Grape              8            5      Fruit  2.236068\n",
      "2        Nut              3            6    Protein  3.605551\n",
      "3     Shrimp              2            3    Protein  4.123106\n",
      "4       Fish              3            1    Protein  4.242641\n",
      "5       Bean              3            7  Vegetable  4.242641\n",
      "6      Bacon              1            4    Protein  5.000000\n",
      "7     Banana             10            1      Fruit  5.000000\n",
      "8       Pear             10            7      Fruit  5.000000\n",
      "9   Cucumber              2            8  Vegetable  5.656854\n",
      "10    Cheese              1            1    Protein  5.830952\n",
      "11    Carrot              5           10  Vegetable  6.082763\n",
      "12     Apple             10            9      Fruit  6.403124\n",
      "13    Celery              3           10  Vegetable  6.708204\n",
      "14   Cabbage              1            9  Vegetable  7.071068\n",
      "K=10 Nearest Neighbors:\n",
      "   Food Name  Sugar content  Crunchiness  Food Type  Distance\n",
      "0    Orange              7            3      Fruit  1.414214\n",
      "1     Grape              8            5      Fruit  2.236068\n",
      "2       Nut              3            6    Protein  3.605551\n",
      "3    Shrimp              2            3    Protein  4.123106\n",
      "4      Fish              3            1    Protein  4.242641\n",
      "5      Bean              3            7  Vegetable  4.242641\n",
      "6     Bacon              1            4    Protein  5.000000\n",
      "7    Banana             10            1      Fruit  5.000000\n",
      "8      Pear             10            7      Fruit  5.000000\n",
      "9  Cucumber              2            8  Vegetable  5.656854\n",
      "\n",
      "Food type counts at K=10:\n",
      " Fruit        4\n",
      "Protein      4\n",
      "Vegetable    2\n",
      "Name: Food Type, dtype: int64\n",
      "\n",
      "Minimum K where Protein becomes the majority: 5\n",
      "\n",
      "Food type counts at minimum K for Protein:\n",
      " Protein    3\n",
      "Fruit      2\n",
      "Name: Food Type, dtype: int64\n",
      "[(5, Protein    3\n",
      "Fruit      2\n",
      "Name: Food Type, dtype: int64), (6, Protein      3\n",
      "Fruit        2\n",
      "Vegetable    1\n",
      "Name: Food Type, dtype: int64), (7, Protein      4\n",
      "Fruit        2\n",
      "Vegetable    1\n",
      "Name: Food Type, dtype: int64), (8, Protein      4\n",
      "Fruit        3\n",
      "Vegetable    1\n",
      "Name: Food Type, dtype: int64), (11, Protein      5\n",
      "Fruit        4\n",
      "Vegetable    2\n",
      "Name: Food Type, dtype: int64), (12, Protein      5\n",
      "Fruit        4\n",
      "Vegetable    3\n",
      "Name: Food Type, dtype: int64)]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Review the table labeled Figure 1: Food Type Prediction. \n",
    "A K-Nearest Neighbor (KNN) model is used to predict food type based \n",
    "on sugar content and crunchiness for the following training set. \n",
    "If K is set to 10 and the model uses Euclidean distance, which food type will be predicted for Tomato?\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Food dataset with sugar content and crunchiness\n",
    "data = {\n",
    "    'Food Name': ['Orange', 'Grape', 'Nut', 'Shrimp', 'Fish', 'Bean', 'Bacon', 'Banana', 'Pear', \n",
    "                  'Cucumber', 'Cheese', 'Carrot', 'Apple', 'Celery', 'Cabbage', 'Tomato'],\n",
    "    'Sugar content': [7, 8, 3, 2, 3, 3, 1, 10, 10, 2, 1, 5, 10, 3, 1, 6],\n",
    "    'Crunchiness': [3, 5, 6, 3, 1, 7, 4, 1, 7, 8, 1, 10, 9, 10, 9, 4],\n",
    "    'Food Type': ['Fruit', 'Fruit', 'Protein', 'Protein', 'Protein', 'Vegetable', 'Protein', \n",
    "                  'Fruit', 'Fruit', 'Vegetable', 'Protein', 'Vegetable', 'Fruit', 'Vegetable', \n",
    "                  'Vegetable', 'Unknown']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Coordinates of the Tomato\n",
    "tomato = np.array([6, 4])\n",
    "\n",
    "# Function to calculate Euclidean distance\n",
    "def euclidean_distance(row, point):\n",
    "    return np.sqrt((row['Sugar content'] - point[0])**2 + (row['Crunchiness'] - point[1])**2)\n",
    "\n",
    "# Calculate the Euclidean distance from Tomato to all other foods\n",
    "df['Distance'] = df.apply(lambda row: euclidean_distance(row, tomato), axis=1)\n",
    "\n",
    "# Sort by distance and get the K nearest neighbors\n",
    "def find_k_nearest_neighbors(K):\n",
    "    return df[df['Food Name'] != 'Tomato'].sort_values(by='Distance').head(K)\n",
    "\n",
    "# Calculate result using K = 10\n",
    "nearest_neighbors_k10 = find_k_nearest_neighbors(10)\n",
    "\n",
    "# Count the food types in the 10 nearest neighbors\n",
    "food_type_counts_k10 = nearest_neighbors_k10['Food Type'].value_counts()\n",
    "\n",
    "# Search for the K where Protein becomes the majority\n",
    "def find_k_for_protein():\n",
    "    k = 1\n",
    "    while k <= len(df) - 1:\n",
    "        nearest_neighbors = find_k_nearest_neighbors(k)\n",
    "        food_type_counts = nearest_neighbors['Food Type'].value_counts()\n",
    "        if 'Protein' in food_type_counts and food_type_counts['Protein'] > food_type_counts.get('Fruit', 0):\n",
    "            return k, food_type_counts\n",
    "        k += 1\n",
    "    return None, None\n",
    "\n",
    "# Find the minimum K where Protein becomes the majority\n",
    "min_k_protein, food_type_counts_at_k = find_k_for_protein()\n",
    "\n",
    "print(df.sort_values(by='Distance'))\n",
    "print(\"K=10 Nearest Neighbors:\\n\", nearest_neighbors_k10)\n",
    "print(\"\\nFood type counts at K=10:\\n\", food_type_counts_k10)\n",
    "print(\"\\nMinimum K where Protein becomes the majority:\", min_k_protein)\n",
    "print(\"\\nFood type counts at minimum K for Protein:\\n\", food_type_counts_at_k)\n",
    "\n",
    "\n",
    "'''\n",
    "q2\n",
    "Review the table labeled Figure 1: Food Type Prediction. \n",
    "A K-Nearest Neighbor (KNN) model is used to predict food \n",
    "type based on sugar content and crunchiness for the following training set. \n",
    "If the model uses Euclidean distance, which value should be given \n",
    "to K in order for the model to predict Tomato as a Protein?\n",
    "'''\n",
    "\n",
    "# Search for all K where Protein becomes the majority\n",
    "def find_all_k_for_protein_prediction():\n",
    "    protein_ks = []\n",
    "    for k in range(1, len(df)):\n",
    "        nearest_neighbors = find_k_nearest_neighbors(k)\n",
    "        food_type_counts = nearest_neighbors['Food Type'].value_counts()\n",
    "        if 'Protein' in food_type_counts and food_type_counts['Protein'] > food_type_counts.get('Fruit', 0):\n",
    "            protein_ks.append((k, food_type_counts))\n",
    "    return protein_ks\n",
    "\n",
    "# Find all K values where Protein becomes the majority\n",
    "all_k_protein_predictions = find_all_k_for_protein_prediction()\n",
    "\n",
    "print(all_k_protein_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1f8a09e-e757-49d7-bc6d-941b0bb88480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'P(drive ‚à© dorm | college) * P(college)': 0.013800000000000002, 'P(drive ‚à© dorm | high school) * P(high school)': 0.012}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "q3\n",
    "Suppose 30% of college students live in a dorm, but only 10% of high school students live in a dorm. \n",
    "In addition, the percentage of high school students who can drive is 15%, \n",
    "and the percentage of college students who can drive is 23%. \n",
    "One-fifth of the students are college students and the rest are high school students. \n",
    "If a student can drive and lives in the dorm, is the student more likely to be a college or high school student? \n",
    "(You can assume independence between students who live in a dorm and those who can drive.)\n",
    "'''\n",
    "# Import necessary library\n",
    "import numpy as np\n",
    "\n",
    "# Given probabilities\n",
    "P_college = 0.2  # Probability of being a college student\n",
    "P_high_school = 0.8  # Probability of being a high school student\n",
    "\n",
    "P_dorm_college = 0.3  # Probability of living in a dorm, given college student\n",
    "P_dorm_high_school = 0.1  # Probability of living in a dorm, given high school student\n",
    "\n",
    "P_drive_college = 0.23  # Probability of being able to drive, given college student\n",
    "P_drive_high_school = 0.15  # Probability of being able to drive, given high school student\n",
    "\n",
    "# Calculate P(drive ‚à© dorm | college) and P(drive ‚à© dorm | high school)\n",
    "P_drive_dorm_college = P_drive_college * P_dorm_college\n",
    "P_drive_dorm_high_school = P_drive_high_school * P_dorm_high_school\n",
    "\n",
    "# Numerators of Bayes' Theorem for college and high school\n",
    "numerator_college = P_drive_dorm_college * P_college\n",
    "numerator_high_school = P_drive_dorm_high_school * P_high_school\n",
    "\n",
    "# Display the results for comparison\n",
    "result = {\n",
    "    \"P(drive ‚à© dorm | college) * P(college)\": numerator_college,\n",
    "    \"P(drive ‚à© dorm | high school) * P(high school)\": numerator_high_school\n",
    "}\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd21236e-7933-4bbf-b4a5-88d202c8cb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure 2: Rainy Day Prediction Dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"./q4and5.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "print(\"Figure 2: Rainy Day Prediction Dataset.\")\n",
    "Image(url= \"./q4and5.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff7e08f6-ae56-4383-bfb8-023ed50489e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Probability of sunshine, wind, high atmosphere, and high temperature on a rainy day: 0.1171875\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "q4\n",
    "Review the table labeled Figure 2: Rainy Day Prediction Dataset. \n",
    "You need a model to predict if a day is rainy or not based on the following \n",
    "conditions: sunshine, wind, atmosphere, and temperature. In a Na√Øve Bayes classifier, \n",
    "given a rainy day, what is the estimated probability of having sunshine, wind, high atmosphere and high temperature?\n",
    "'''\n",
    "# Given conditional probabilities from the table\n",
    "\n",
    "# Probability of Sunshine on a Rainy Day: 2 out of 8 (Yes = 2, No = 6)\n",
    "P_sunshine_given_rainy = 2 / 8\n",
    "\n",
    "# Probability of Wind on a Rainy Day: 6 out of 8 (Yes = 6, No = 2)\n",
    "P_wind_given_rainy = 6 / 8\n",
    "\n",
    "# Probability of High Atmosphere on a Rainy Day: 8 out of 8 (High = 8, Low = 0)\n",
    "P_high_atmosphere_given_rainy = 8 / 8\n",
    "\n",
    "# Probability of High Temperature on a Rainy Day: 5 out of 8 (High = 5, Low = 3)\n",
    "P_high_temperature_given_rainy = 5 / 8\n",
    "\n",
    "# Now multiply the probabilities together (Na√Øve Bayes assumes conditional independence)\n",
    "P_total = P_sunshine_given_rainy * P_wind_given_rainy * P_high_atmosphere_given_rainy * P_high_temperature_given_rainy\n",
    "\n",
    "# Print the final estimated probability\n",
    "print(\"Estimated Probability of sunshine, wind, high atmosphere, and high temperature on a rainy day:\", P_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba5988e9-3f17-4fe8-ad6d-632e956bb92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of Rainy: 0.012620192307692308\n",
      "Probability of Not Rainy: 0.021367521367521368\n",
      "Prediction: Not Rainy\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "q5\n",
    "Review the table labeled Figure 2: Rainy Day Prediction Dataset. \n",
    "A Na√Øve Bayes classifier is trained for the dataset in order \n",
    "to predict whether a day is rainy or not. If on a particular day the weather is sunny, \n",
    "the temperature is low, the atmosphere is high, and there is no wind, what will the model predict?\n",
    "'''\n",
    "\n",
    "# Given counts from the table\n",
    "\n",
    "# Prior probabilities\n",
    "total_rainy = 8 + 6  # Rainy yes = 8, Rainy no = 6\n",
    "total_not_rainy = 8 + 4  # Not Rainy yes = 8, Not Rainy no = 4\n",
    "total_days = total_rainy + total_not_rainy\n",
    "\n",
    "P_rainy = total_rainy / total_days\n",
    "P_not_rainy = total_not_rainy / total_days\n",
    "\n",
    "# Conditional probabilities for Rainy\n",
    "P_sunny_given_rainy = 2 / 8  # Sunny = Yes for rainy days\n",
    "P_no_wind_given_rainy = 2 / 8  # Wind = No for rainy days\n",
    "P_high_atmosphere_given_rainy = 8 / 8  # High Atmosphere for rainy days\n",
    "P_low_temp_given_rainy = 3 / 8  # Low temperature for rainy days\n",
    "\n",
    "# Conditional probabilities for Not Rainy\n",
    "P_sunny_given_not_rainy = 8 / 12  # Sunny = Yes for non-rainy days\n",
    "P_no_wind_given_not_rainy = 10 / 12  # Wind = No for non-rainy days\n",
    "P_high_atmosphere_given_not_rainy = 2 / 12  # High Atmosphere for non-rainy days\n",
    "P_low_temp_given_not_rainy = 6 / 12  # Low temperature for non-rainy days\n",
    "\n",
    "# Na√Øve Bayes prediction for Rainy\n",
    "P_rainy_given_weather = (\n",
    "    P_rainy *\n",
    "    P_sunny_given_rainy *\n",
    "    P_no_wind_given_rainy *\n",
    "    P_high_atmosphere_given_rainy *\n",
    "    P_low_temp_given_rainy\n",
    ")\n",
    "\n",
    "# Na√Øve Bayes prediction for Not Rainy\n",
    "P_not_rainy_given_weather = (\n",
    "    P_not_rainy *\n",
    "    P_sunny_given_not_rainy *\n",
    "    P_no_wind_given_not_rainy *\n",
    "    P_high_atmosphere_given_not_rainy *\n",
    "    P_low_temp_given_not_rainy\n",
    ")\n",
    "\n",
    "# Compare probabilities\n",
    "if P_rainy_given_weather > P_not_rainy_given_weather:\n",
    "    prediction = \"Rainy\"\n",
    "else:\n",
    "    prediction = \"Not Rainy\"\n",
    "\n",
    "# Print results\n",
    "print(f\"Probability of Rainy: {P_rainy_given_weather}\")\n",
    "print(f\"Probability of Not Rainy: {P_not_rainy_given_weather}\")\n",
    "print(f\"Prediction: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f961b75-c7b8-4106-9928-907aabb7609d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Figure 3: Car Dataset Used By Police Force.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"./q6and7.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "print(\" Figure 3: Car Dataset Used By Police Force.\")\n",
    "Image(url= \"./q6and7.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a15ce99b-f525-435c-b2f6-4fa400f9510e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stolen cars: 5\n",
      "Stolen cars with plate number: 1\n",
      "Probability that a stolen car has a plate number: 0.2\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "q6\n",
    "Review the table labeled Figure 3: Car Dataset Used By Police Force. \n",
    "Attribute A shows if a car was speeding, \n",
    "Attribute B shows if a car has a plate number, \n",
    "Attribute C shows if a car is new, and Class Attribute shows if a car was stolen. \n",
    "\n",
    "If a car is stolen, what is the probability that the car has a plate number?\n",
    "'''\n",
    "\n",
    "# Data from the table\n",
    "data = {\n",
    "    'A': ['F', 'F', 'F', 'F', 'F', 'T', 'T', 'T', 'T', 'T'],\n",
    "    'B': ['F', 'F', 'T', 'T', 'F', 'F', 'F', 'F', 'T', 'F'],\n",
    "    'C': ['F', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T'],\n",
    "    'Class': ['Y', 'N', 'N', 'N', 'Y', 'Y', 'N', 'N', 'Y', 'Y']\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 1: Count total stolen cars (Class = Y)\n",
    "total_stolen = df[df['Class'] == 'Y'].shape[0]\n",
    "\n",
    "# Step 2: Count stolen cars with a plate number (B = T and Class = Y)\n",
    "stolen_with_plate = df[(df['Class'] == 'Y') & (df['B'] == 'T')].shape[0]\n",
    "\n",
    "# Step 3: Calculate the probability\n",
    "P_plate_given_stolen = stolen_with_plate / total_stolen\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total stolen cars: {total_stolen}\")\n",
    "print(f\"Stolen cars with plate number: {stolen_with_plate}\")\n",
    "print(f\"Probability that a stolen car has a plate number: {P_plate_given_stolen}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bcde180-8474-44f6-8ca3-3ebc3ad8c9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of stolen given conditions: 0.017492711370262388\n",
      "Probability of not stolen given conditions: 0.017492711370262388\n",
      "Prediction: Tie\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "q7\n",
    "Review the table labeled Figure 3: Car Dataset Used By Police Force. \n",
    "Attribute A shows if a car was speeding, \n",
    "Attribute B shows if a car has a plate number, \n",
    "Attribute C shows if a car is new, and Class Attribute shows if a car was stolen. \n",
    "Consider if one of the probabilities is zero while applying Naive Bayes, use Laplace smoothing.\n",
    "\n",
    "If a Na√Øve Bayes model is trained for this dataset,\n",
    "what will be the Class Attribute prediction for an old car that was not speeding and has a plate number?\n",
    "'''\n",
    "# Step 1: Calculate prior probabilities\n",
    "P_stolen = df[df['Class'] == 'Y'].shape[0] / df.shape[0]\n",
    "P_not_stolen = df[df['Class'] == 'N'].shape[0] / df.shape[0]\n",
    "\n",
    "# Step 2: Calculate conditional probabilities with Laplace smoothing (for binary attributes)\n",
    "def laplace_smoothing(feature, value, target_class, df, k=2):\n",
    "    count_X_given_class = df[(df[feature] == value) & (df['Class'] == target_class)].shape[0]\n",
    "    count_class = df[df['Class'] == target_class].shape[0]\n",
    "    return (count_X_given_class + 1) / (count_class + k)\n",
    "\n",
    "# Conditional probabilities for stolen (Class = Y)\n",
    "P_A_F_given_stolen = laplace_smoothing('A', 'F', 'Y', df)  # A = F (Not speeding)\n",
    "P_B_T_given_stolen = laplace_smoothing('B', 'T', 'Y', df)  # B = T (Has plate number)\n",
    "P_C_F_given_stolen = laplace_smoothing('C', 'F', 'Y', df)  # C = F (Old car)\n",
    "\n",
    "# Conditional probabilities for not stolen (Class = N)\n",
    "P_A_F_given_not_stolen = laplace_smoothing('A', 'F', 'N', df)\n",
    "P_B_T_given_not_stolen = laplace_smoothing('B', 'T', 'N', df)\n",
    "P_C_F_given_not_stolen = laplace_smoothing('C', 'F', 'N', df)\n",
    "\n",
    "# Step 3: Calculate Na√Øve Bayes probabilities\n",
    "P_stolen_given_ABC = (\n",
    "    P_stolen * P_A_F_given_stolen * P_B_T_given_stolen * P_C_F_given_stolen\n",
    ")\n",
    "\n",
    "P_not_stolen_given_ABC = (\n",
    "    P_not_stolen * P_A_F_given_not_stolen * P_B_T_given_not_stolen * P_C_F_given_not_stolen\n",
    ")\n",
    "\n",
    "# Step 4: Make the prediction\n",
    "if P_stolen_given_ABC > P_not_stolen_given_ABC:\n",
    "    prediction = \"Stolen (Y)\"\n",
    "elif P_stolen_given_ABC == P_not_stolen_given_ABC:\n",
    "    prediction = \"Tie\"\n",
    "else:\n",
    "    prediction = \"Not Stolen (N)\"\n",
    "\n",
    "# Print results\n",
    "print(f\"Probability of stolen given conditions: {P_stolen_given_ABC}\")\n",
    "print(f\"Probability of not stolen given conditions: {P_not_stolen_given_ABC}\")\n",
    "print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dee43389-ae99-4df1-9f2e-d8417e67923e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure 4: Neural Network\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"./q8.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "print(\"Figure 4: Neural Network\")\n",
    "Image(url= \"./q8.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23b454cd-4caf-4685-bf01-3c1cc3127eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated w5: 0.35891647971788465\n",
      "Rounded w5: 0.36\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "q8\n",
    "Review the figure labeled Figure 4: Neural Network. \n",
    "The given neural network finished a forward pass and now will perform a backpropagation to tune its parameters. \n",
    "The network uses a logistic activation function, $f(x)=\\frac{1}{(1+{e}^{hx})}$ with a learning rate of 0.5, \n",
    "and loss is calculated using a squared error function, $ l=\\frac{1}{2}(target-output{)}^{2}$. \n",
    "\n",
    "Given the inputs, ground truth output, weights, and biases listed below, what will the value of w5 be after the first iteration of backpropagation? (Round your answer to the nearest hundredth.)\n",
    "\n",
    "Inputs = $ {I}_{1}=0.05,{I}_{2}=0.1$\n",
    "Weights = $ {w}_{1}=0.15,{w}_{2}=0.2,{w}_{3}=0.25,{w}_{4}=0.30,{w}_{5}=0.40,{w}_{6}=0.45$\n",
    "Biases = $ {B}_{1}=0.35,{B}_{2}=0.6$\n",
    "Learning rate: ùúÇ = 0.5\n",
    "Ground-truth output t = 0.01\n",
    "\n",
    "Note: Your answer should be in format X.X or X.XX (depending on precision required on decimal places).\n",
    "'''\n",
    "import math\n",
    "\n",
    "# Activation function (logistic sigmoid function)\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "# Derivative of the sigmoid function\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Inputs and weights from the problem statement\n",
    "I1 = 0.05  # Input 1\n",
    "I2 = 0.10  # Input 2\n",
    "w1 = 0.15  # Weight from I1 to H1\n",
    "w2 = 0.20  # Weight from I2 to H1\n",
    "w3 = 0.25  # Weight from I1 to H2\n",
    "w4 = 0.30  # Weight from I2 to H2\n",
    "w5 = 0.40  # Weight from H1 to output\n",
    "w6 = 0.45  # Weight from H2 to output\n",
    "B1 = 0.35  # Bias for hidden layer\n",
    "B2 = 0.6   # Bias for output layer\n",
    "learning_rate = 0.5  # Learning rate\n",
    "target_output = 0.01  # Ground-truth target output\n",
    "\n",
    "# Step 1: Forward pass to calculate hidden layer activations\n",
    "# Hidden layer node H1\n",
    "H1_input = I1 * w1 + I2 * w2 + B1  # Input to H1\n",
    "H1 = sigmoid(H1_input)  # Activation at H1\n",
    "\n",
    "# Hidden layer node H2\n",
    "H2_input = I1 * w3 + I2 * w4 + B1  # Input to H2\n",
    "H2 = sigmoid(H2_input)  # Activation at H2\n",
    "\n",
    "# Step 2: Forward pass to calculate the output layer activation\n",
    "O_input = H1 * w5 + H2 * w6 + B2  # Input to output node O\n",
    "O = sigmoid(O_input)  # Output activation\n",
    "\n",
    "# Step 3: Calculate the error (squared error loss)\n",
    "error = 0.5 * (target_output - O) ** 2  # Squared error loss\n",
    "\n",
    "# Step 4: Backpropagation - calculate gradient for w5\n",
    "# Derivative of the loss with respect to the output O\n",
    "d_loss_d_O = -(target_output - O)\n",
    "\n",
    "# Derivative of the output O with respect to weight w5\n",
    "d_O_d_w5 = H1 * sigmoid_derivative(O)\n",
    "\n",
    "# Full gradient for w5\n",
    "gradient_w5 = d_loss_d_O * d_O_d_w5\n",
    "\n",
    "# Step 5: Update w5 using the learning rate\n",
    "w5_updated = w5 - learning_rate * gradient_w5\n",
    "\n",
    "# Print the updated weight w5 and rounded result to the nearest hundredth\n",
    "print(\"Updated w5:\", w5_updated)\n",
    "print(\"Rounded w5:\", round(w5_updated, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cad4fbe-ef35-4488-a72e-41be03a6bab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure 5: Support Vector Machine (SVM) Dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"./q9.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "print(\"Figure 5: Support Vector Machine (SVM) Dataset\")\n",
    "Image(url= \"./q9.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ff73663-4ed8-49cd-b1c6-acd15dc93733",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input z must be 2D, not 1D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(xx, yy, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mg--\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransformed x^2 boundary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Plot the decision boundary\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m plt\u001b[38;5;241m.\u001b[39mcontour(xx, yy, Z\u001b[38;5;241m.\u001b[39mreshape(xx\u001b[38;5;241m.\u001b[39mshape), levels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m], colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyles\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Add labels and legend\u001b[39;00m\n\u001b[1;32m     42\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cse572/lib/python3.11/site-packages/matplotlib/pyplot.py:3143\u001b[0m, in \u001b[0;36mcontour\u001b[0;34m(data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3141\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mcontour)\n\u001b[1;32m   3142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontour\u001b[39m(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m QuadContourSet:\n\u001b[0;32m-> 3143\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m gca()\u001b[38;5;241m.\u001b[39mcontour(\n\u001b[1;32m   3144\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   3145\u001b[0m     )\n\u001b[1;32m   3146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m __ret\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   3147\u001b[0m         sci(__ret)\n",
      "File \u001b[0;32m~/anaconda3/envs/cse572/lib/python3.11/site-packages/matplotlib/__init__.py:1473\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1472\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1473\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\n\u001b[1;32m   1474\u001b[0m             ax,\n\u001b[1;32m   1475\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args),\n\u001b[1;32m   1476\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: sanitize_sequence(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[1;32m   1478\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1479\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1480\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/anaconda3/envs/cse572/lib/python3.11/site-packages/matplotlib/axes/_axes.py:6659\u001b[0m, in \u001b[0;36mAxes.contour\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6650\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6651\u001b[0m \u001b[38;5;124;03mPlot contour lines.\u001b[39;00m\n\u001b[1;32m   6652\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6656\u001b[0m \u001b[38;5;124;03m%(contour_doc)s\u001b[39;00m\n\u001b[1;32m   6657\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6658\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilled\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 6659\u001b[0m contours \u001b[38;5;241m=\u001b[39m mcontour\u001b[38;5;241m.\u001b[39mQuadContourSet(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   6660\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_autoscale_view()\n\u001b[1;32m   6661\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m contours\n",
      "File \u001b[0;32m~/anaconda3/envs/cse572/lib/python3.11/site-packages/matplotlib/contour.py:813\u001b[0m, in \u001b[0;36mContourSet.__init__\u001b[0;34m(self, ax, levels, filled, linewidths, linestyles, hatches, alpha, origin, extent, cmap, colors, norm, vmin, vmax, extend, antialiased, nchunk, locator, transform, negative_linestyles, clip_path, *args, **kwargs)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnegative_linestyles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnegative_linestyles \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    811\u001b[0m         mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontour.negative_linestyle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 813\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_args(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_levels()\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextend \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/cse572/lib/python3.11/site-packages/matplotlib/contour.py:1470\u001b[0m, in \u001b[0;36mQuadContourSet._process_args\u001b[0;34m(self, corner_mask, algorithm, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m         corner_mask \u001b[38;5;241m=\u001b[39m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontour.corner_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_corner_mask \u001b[38;5;241m=\u001b[39m corner_mask\n\u001b[0;32m-> 1470\u001b[0m x, y, z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_contour_args(args, kwargs)\n\u001b[1;32m   1472\u001b[0m contour_generator \u001b[38;5;241m=\u001b[39m contourpy\u001b[38;5;241m.\u001b[39mcontour_generator(\n\u001b[1;32m   1473\u001b[0m     x, y, z, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_algorithm, corner_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_corner_mask,\n\u001b[1;32m   1474\u001b[0m     line_type\u001b[38;5;241m=\u001b[39mcontourpy\u001b[38;5;241m.\u001b[39mLineType\u001b[38;5;241m.\u001b[39mSeparateCode,\n\u001b[1;32m   1475\u001b[0m     fill_type\u001b[38;5;241m=\u001b[39mcontourpy\u001b[38;5;241m.\u001b[39mFillType\u001b[38;5;241m.\u001b[39mOuterCode,\n\u001b[1;32m   1476\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnchunk)\n\u001b[1;32m   1478\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_transform()\n",
      "File \u001b[0;32m~/anaconda3/envs/cse572/lib/python3.11/site-packages/matplotlib/contour.py:1510\u001b[0m, in \u001b[0;36mQuadContourSet._contour_args\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1508\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m<\u001b[39m nargs \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m   1509\u001b[0m     x, y, z_orig, \u001b[38;5;241m*\u001b[39margs \u001b[38;5;241m=\u001b[39m args\n\u001b[0;32m-> 1510\u001b[0m     x, y, z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_xyz(x, y, z_orig, kwargs)\n\u001b[1;32m   1512\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _api\u001b[38;5;241m.\u001b[39mnargs_error(fn, takes\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom 1 to 4\u001b[39m\u001b[38;5;124m\"\u001b[39m, given\u001b[38;5;241m=\u001b[39mnargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/cse572/lib/python3.11/site-packages/matplotlib/contour.py:1536\u001b[0m, in \u001b[0;36mQuadContourSet._check_xyz\u001b[0;34m(self, x, y, z, kwargs)\u001b[0m\n\u001b[1;32m   1533\u001b[0m z \u001b[38;5;241m=\u001b[39m ma\u001b[38;5;241m.\u001b[39masarray(z)\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m z\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput z must be 2D, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mz\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m z\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m z\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1538\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput z must be at least a (2, 2) shaped array, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1539\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut has shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mz\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Input z must be 2D, not 1D"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "q9\n",
    "Review the table labeled Figure 5: Support Vector Machine (SVM) Dataset. \n",
    "Your friend has asked you to train a Support Vector Machine (SVM) on the provided dataset. \n",
    "You check the dataset, which is one dimensional, and understand that there is no \n",
    "hyperplane that can completely separate the two classes. Therefore, linear SVM is not the best option. \n",
    "If you transform the data into two dimensions [(x)(x,x2)], and you decide to use non-linear SVM, \n",
    "which hyperplane will the SVM provide for separating the two classes?\n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Original dataset\n",
    "X = np.array([[-3], [-2], [-1], [0], [1], [2]])\n",
    "y = np.array([-1, -1, 1, 1, 1, -1])  # Class labels (-1 for negative, 1 for positive)\n",
    "\n",
    "# Transform the data to 2D using the (x, x^2) transformation\n",
    "X_transformed = np.hstack((X, X ** 2))\n",
    "\n",
    "# Train a non-linear SVM with a polynomial kernel\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_transformed, y)\n",
    "\n",
    "# Create a mesh grid to visualize the decision boundary\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "xx = np.linspace(x_min, x_max, 500)\n",
    "yy = xx ** 2  # Quadratic transformation\n",
    "\n",
    "# Predict using the SVM model\n",
    "Z = svm_model.decision_function(np.c_[xx, yy])\n",
    "\n",
    "# Plotting\n",
    "plt.scatter(X_transformed[y == 1][:, 0], X_transformed[y == 1][:, 1], color='b', label='Positive Class (+)')\n",
    "plt.scatter(X_transformed[y == -1][:, 0], X_transformed[y == -1][:, 1], color='r', label='Negative Class (-)')\n",
    "plt.plot(xx, yy, 'g--', label='Transformed x^2 boundary')\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.contour(xx, yy, Z.reshape(xx.shape), levels=[0], colors='k', linestyles=['-'])\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('X^2')\n",
    "plt.title('SVM Decision Boundary in Transformed Space')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c67d5d96-5fa1-4537-8e11-3158ecc9dbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data (x, x^2, class):\n",
      "(-3, 9, -1)\n",
      "(-2, 4, -1)\n",
      "(-1, 1, 1)\n",
      "(0, 0, 1)\n",
      "(1, 1, 1)\n",
      "(2, 4, -1)\n",
      "\n",
      "Estimated Decision Boundary: x^2 = 2.5\n",
      "\n",
      "Verifying Decision Boundary:\n",
      "Negative point (-3, 9) is correctly classified above the boundary.\n",
      "Negative point (-2, 4) is correctly classified above the boundary.\n",
      "Positive point (-1, 1) is correctly classified below the boundary.\n",
      "Positive point (0, 0) is correctly classified below the boundary.\n",
      "Positive point (1, 1) is correctly classified below the boundary.\n",
      "Negative point (2, 4) is correctly classified above the boundary.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define the original dataset (1D data)\n",
    "data = [\n",
    "    (-3, -1),  # (x, class)\n",
    "    (-2, -1),\n",
    "    (-1,  1),\n",
    "    ( 0,  1),\n",
    "    ( 1,  1),\n",
    "    ( 2, -1)\n",
    "]\n",
    "\n",
    "# Step 2: Manually transform the data (x -> (x, x^2))\n",
    "transformed_data = [(x, x**2, label) for x, label in data]\n",
    "\n",
    "# Step 3: Display the transformed dataset\n",
    "print(\"Transformed Data (x, x^2, class):\")\n",
    "for x, x2, label in transformed_data:\n",
    "    print(f\"({x}, {x2}, {label})\")\n",
    "\n",
    "# Step 4: Manually estimate the decision boundary by analyzing the transformed data\n",
    "# We know that the negative class (-1) and positive class (+1) are not linearly separable in 1D,\n",
    "# but in the transformed 2D space, they can be separated by a boundary like x^2 = c.\n",
    "\n",
    "# Let‚Äôs manually calculate and check for a reasonable boundary:\n",
    "# We will check where the separation lies between (x, x^2) points of different classes\n",
    "\n",
    "# Negative class points:\n",
    "neg_class_points = [(x, x2) for x, x2, label in transformed_data if label == -1]\n",
    "\n",
    "# Positive class points:\n",
    "pos_class_points = [(x, x2) for x, x2, label in transformed_data if label == 1]\n",
    "\n",
    "# Step 5: Estimate the decision boundary (x^2 = 2.5 is reasonable from the transformed data)\n",
    "decision_boundary_x2 = 2.5\n",
    "\n",
    "print(f\"\\nEstimated Decision Boundary: x^2 = {decision_boundary_x2}\")\n",
    "\n",
    "# Step 6: Now let's verify the decision boundary manually\n",
    "# If x^2 = 2.5 is the decision boundary, it should separate the positive and negative class points.\n",
    "# Positive points should lie below this boundary, and negative points should lie above.\n",
    "\n",
    "print(\"\\nVerifying Decision Boundary:\")\n",
    "for x, x2, label in transformed_data:\n",
    "    if label == 1 and x2 < decision_boundary_x2:\n",
    "        print(f\"Positive point ({x}, {x2}) is correctly classified below the boundary.\")\n",
    "    elif label == -1 and x2 > decision_boundary_x2:\n",
    "        print(f\"Negative point ({x}, {x2}) is correctly classified above the boundary.\")\n",
    "    else:\n",
    "        print(f\"Point ({x}, {x2}) might be misclassified.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59c21a87-98cd-41ad-a7eb-88c297c4bf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative class support vectors: [(-3, 9), (-2, 4), (2, 4)]\n",
      "Positive class support vectors: [(-1, 1), (0, 0), (1, 1)]\n",
      "[9, 4, 4]\n",
      "4\n",
      "[1, 0, 1]\n",
      "1\n",
      "Optimal decision boundary (x^2): 2.5\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define the transformed dataset (x -> (x, x^2))\n",
    "transformed_data = [\n",
    "    (-3, 9, -1),  # (x, x^2, class)\n",
    "    (-2, 4, -1),\n",
    "    (-1, 1, 1),\n",
    "    ( 0, 0, 1),\n",
    "    ( 1, 1, 1),\n",
    "    ( 2, 4, -1)\n",
    "]\n",
    "\n",
    "# Step 2: Identify the support vectors\n",
    "neg_class_support_vectors = [(x, x2) for x, x2, label in transformed_data if label == -1]\n",
    "pos_class_support_vectors = [(x, x2) for x, x2, label in transformed_data if label == 1]\n",
    "\n",
    "print(\"Negative class support vectors:\", neg_class_support_vectors)\n",
    "print(\"Positive class support vectors:\", pos_class_support_vectors)\n",
    "\n",
    "# Step 3: Calculate the decision boundary as the midpoint between the support vectors\n",
    "neg_class_x2 = [x2 for x, x2 in neg_class_support_vectors]\n",
    "pos_class_x2 = [x2 for x, x2 in pos_class_support_vectors]\n",
    "print(neg_class_x2)\n",
    "print(min(neg_class_x2))\n",
    "print(pos_class_x2)\n",
    "print(max(pos_class_x2))\n",
    "# The boundary is the midpoint between the closest points from both classes\n",
    "decision_boundary_x2 = (min(neg_class_x2) + max(pos_class_x2)) / 2\n",
    "\n",
    "print(f\"Optimal decision boundary (x^2): {decision_boundary_x2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dbb11a5-01a4-458e-9b71-c888b6a1912f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data (x, x^2, class):\n",
      "(-3, 9, -1)\n",
      "(-2, 4, -1)\n",
      "(-1, 1, 1)\n",
      "(0, 0, 1)\n",
      "(1, 1, 1)\n",
      "(2, 4, -1)\n",
      "\n",
      "Negative class support vectors: [(-3, 9), (-2, 4), (2, 4)]\n",
      "Positive class support vectors: [(-1, 1), (0, 0), (1, 1)]\n",
      "\n",
      "Support vectors: [(-2, 4), (2, 4), (-1, 1), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "q10\n",
    "\n",
    "Review the table labeled Figure 5: Support Vector Machine (SVM) Dataset. \n",
    "Your friend has asked you to train a Support Vector Machine (SVM) on the provided dataset. \n",
    "You check the dataset, which is one dimensional, and understand that there is no hyperplane \n",
    "that can completely separate the two classes. Therefore, linear SVM is not the best option. \n",
    "If you transform the data into two dimensions $ [(x)\\to (x,{x}^{2})]$ and you decide to use non-linear SVM, \n",
    "which points will be support vectors?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Define the original dataset (1D data)\n",
    "data = [\n",
    "    (-3, -1),  # (x, class)\n",
    "    (-2, -1),\n",
    "    (-1,  1),\n",
    "    ( 0,  1),\n",
    "    ( 1,  1),\n",
    "    ( 2, -1)\n",
    "]\n",
    "\n",
    "# Step 2: Manually transform the data (x -> (x, x^2))\n",
    "transformed_data = [(x, x**2, label) for x, label in data]\n",
    "\n",
    "# Step 3: Display the transformed dataset\n",
    "print(\"Transformed Data (x, x^2, class):\")\n",
    "for x, x2, label in transformed_data:\n",
    "    print(f\"({x}, {x2}, {label})\")\n",
    "\n",
    "# Step 4: Identify the support vectors manually\n",
    "# Based on the problem's explanation, we expect support vectors to be the points closest to the boundary\n",
    "\n",
    "# Support vectors will likely be:\n",
    "# Negative class: (-2, 4), (2, 4)\n",
    "# Positive class: (-1, 1), (1, 1)\n",
    "\n",
    "neg_class_support_vectors = [(x, x2) for x, x2, label in transformed_data if label == -1]\n",
    "pos_class_support_vectors = [(x, x2) for x, x2, label in transformed_data if label == 1]\n",
    "\n",
    "print(\"\\nNegative class support vectors:\", neg_class_support_vectors)\n",
    "print(\"Positive class support vectors:\", pos_class_support_vectors)\n",
    "\n",
    "# Display likely support vectors\n",
    "support_vectors = [(-2, 4), (2, 4), (-1, 1), (1, 1)]\n",
    "print(\"\\nSupport vectors:\", support_vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09494958-4659-4862-b59b-299e96c6cb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
